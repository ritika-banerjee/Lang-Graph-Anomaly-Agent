{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(r\"D:\\Xempla\\archive\\MetroPT3(AirCompressor).csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b1119",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "start_date = \"2020-02-01\" \n",
    "end_date = \"2020-04-18\"  \n",
    "normal_data = data[(data['timestamp'] >= start_date) & (data['timestamp'] < end_date)]\n",
    "normal_data = normal_data.reset_index(drop=True)\n",
    "\n",
    "print(normal_data.shape)\n",
    "print(normal_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db77e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'TP2',\n",
    "    'TP3',\n",
    "    'H1',\n",
    "    'DV_pressure',\n",
    "    'Reservoirs',\n",
    "    'Oil_temperature',\n",
    "    'Motor_current'\n",
    "]\n",
    "\n",
    "df = normal_data[features]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b221dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal_data.head())\n",
    "print(normal_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "import pandas as pd\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence(data, seq_len):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        seq = data[i:i + seq_len]\n",
    "        sequences.append(seq)\n",
    "        \n",
    "    return np.array(sequences)\n",
    "\n",
    "data_array = df_scaled.to_numpy()\n",
    "print(data_array)\n",
    "print('=' * 20)\n",
    "sequence_length = 60\n",
    "X = create_sequence(data_array, sequence_length)\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print('=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ed0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, RepeatVector, TimeDistributed, Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "time_steps = X.shape[1]\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(time_steps, n_features))\n",
    "encoded = Bidirectional(LSTM(64, activation='tanh', return_sequences=False))(inputs)\n",
    "bottleneck = RepeatVector(time_steps)(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Bidirectional(LSTM(64, activation='tanh', return_sequences=True))(bottleneck)\n",
    "output = TimeDistributed(Dense(n_features))(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, output)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"Min:\", X.min())\n",
    "print(\"Max:\", X.max())\n",
    "print(\"Mean:\", X.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a500e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X[0])  # One sequence\n",
    "plt.title(\"Sample Input Sequence\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Scaled Sensor Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(\n",
    "    X,X,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"autoencoder_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383912c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494226bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "autoencoder = load_model(\"autoencoder_model.keras\")\n",
    "scaler = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbba7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = data[features]\n",
    "data_scaled = scaler.transform(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = create_sequence(data_scaled, seq_len=60)\n",
    "print(\"X_full shape:\", x_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e43b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = autoencoder.predict(x_full, batch_size=128)\n",
    "mse = np.mean((x_full - preds) ** 2, axis=(1, 2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d27108",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(mse, 95)  # top 5% as anomalies\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e174ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(mse, bins=100)\n",
    "plt.axvline(threshold, color='r', linestyle='--')\n",
    "plt.title(\"Reconstruction Loss Distribution\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(r\"archive\\MetroPT3(AirCompressor).csv\", parse_dates=[\"timestamp\"])\n",
    "full_data = full_data[['timestamp'] + features]\n",
    "\n",
    "anomaly_df =  full_data[( full_data[\"timestamp\"] >= \"2020-04-18 00:00:00\") & (full_data[\"timestamp\"] <= \"2020-04-18 23:59:59\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data[(data[\"timestamp\"] >= \"2020-04-18 00:00:00\") & (data[\"timestamp\"] <= \"2020-04-18 23:59:59\")]\n",
    "\n",
    "# Preprocess\n",
    "test_scaled = scaler.transform(test_df[features])\n",
    "test_seq = create_sequence(test_scaled, seq_len=60)\n",
    "\n",
    "# Predict loss\n",
    "reconstructions = autoencoder.predict(test_seq)\n",
    "losses = np.mean((test_seq - reconstructions) ** 2, axis=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a441452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(losses, label=\"Reconstruction Loss\")\n",
    "plt.axhline(threshold, color=\"red\", linestyle=\"--\", label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.title(\"Anomaly Detection in Failure Window\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def evaluate_reconstruction(model, X_test, threshold=None, plot=True):\n",
    "    \"\"\"\n",
    "    Evaluates reconstruction error and detects anomalies.\n",
    "    \n",
    "    Args:\n",
    "        model: trained autoencoder\n",
    "        X_test: test data, shape (samples, time_steps, features)\n",
    "        threshold: if given, use this fixed MSE threshold. Otherwise use IsolationForest.\n",
    "        plot: whether to show plots\n",
    "\n",
    "    Returns:\n",
    "        losses: reconstruction errors\n",
    "        labels: 1 (normal), -1 (anomaly)\n",
    "    \"\"\"\n",
    "    # 1. Predict\n",
    "    reconstructions = model.predict(X_test, verbose=0)\n",
    "\n",
    "    # 2. Compute reconstruction losses (MSE per sequence)\n",
    "    losses = np.mean((X_test - reconstructions) ** 2, axis=(1, 2))\n",
    "\n",
    "    # 3. Detect anomalies\n",
    "    if threshold is not None:\n",
    "        labels = np.where(losses > threshold, -1, 1)  # -1: anomaly\n",
    "    else:\n",
    "        iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "        labels = iso_forest.fit_predict(losses.reshape(-1, 1))\n",
    "\n",
    "    # 4. Plot\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(losses, label=\"Reconstruction Loss\")\n",
    "        if threshold:\n",
    "            plt.axhline(threshold, color=\"red\", linestyle=\"--\", label=\"Threshold\")\n",
    "        plt.title(\"Reconstruction Losses with Anomaly Labels\")\n",
    "        plt.xlabel(\"Sequence Index\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return losses, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4de72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, labels = evaluate_reconstruction(autoencoder, test_seq, threshold=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf0587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
